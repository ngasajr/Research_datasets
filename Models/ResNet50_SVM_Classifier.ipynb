{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,Adadelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import randint\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f701e1",
   "metadata": {},
   "source": [
    "#### 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = None  # TODO: Specify img_width, img_height\n",
    "epochs = None  # TODO: Specify epochs\n",
    "INIT_LR = None  # TODO: Specify INIT_LR\n",
    "input_shape = None # TODO: Specify input_shape\n",
    "\n",
    "# Where to save model\n",
    "filepath1 = None  # TODO: Specify filepath1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76161217",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab125cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'rwbc_datasets/train'\n",
    "test_data_dir = 'rwbc_datasets/test'\n",
    "\n",
    "\n",
    "num_classes = 19\n",
    "FREEZE_LAYERS = 2\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "  input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "  input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7716fac-0010-49b0-b98e-53be2259edde",
   "metadata": {},
   "source": [
    "#### 1. Data preparing <a name=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965883bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 45, # random rotation btw 0 t0 45\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c857445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    shuffle=True,\n",
    "    batch_size = None,  # TODO: Specify batch_size\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bea297",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = None,  # TODO: Specify batch_size\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in test_batches:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Building the ResNet50-SVM <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Definition\n",
    "def create_model():\n",
    "    \n",
    "    pretrained = ResNet50(include_top=False, weights='imagenet',input_shape=[img_width, img_height, 3])\n",
    "\n",
    "    for layer in pretrained.layers:\n",
    "        layer.trainable = None  # TODO: Specify True or False\n",
    "            \n",
    "    x = pretrained.output\n",
    "    x = tensorflow.keras.layers.GlobalAveragePooling2D() (x)\n",
    "    x = tensorflow.keras.layers.Flatten()(x)\n",
    "    x = tensorflow.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = tensorflow.keras.layers.Dropout(0.5)(x)\n",
    "    x = tensorflow.keras.layers.Dense(units=128, activation='relu')(x)\n",
    "    x = tensorflow.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = tensorflow.keras.layers.Dense((num_classes),kernel_regularizer=tf.keras.regularizers.l2(0.01), activation=\"softmax\", dtype='float32')(x)\n",
    "        \n",
    "    model1 = tensorflow.keras.Model(pretrained.input, outputs)\n",
    "    return model1\n",
    "\n",
    "model1 = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aac098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compiling\n",
    "model1.compile(optimizer=Adam(learning_rate = INIT_LR),\n",
    "              loss=\"squared_hinge\",\n",
    "              metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['01_Band_neutrophil', '02_Segmented_neutrophil', '03_Eosinophil', '04_Basophil', '05_Lymphocyte', '06_Monocyte', \n",
    "                      '07_Promyelocyte', '08_Myelocyte', '09_Metamyelocyte', '10_Prolymphocyte', '11_Immature_cell', '12_Lymphocyte_variant_form', \n",
    "                      '13_Plasma_cell', '14_Large_granular_lymphocyte', '15_Abnormal_cell', '16_Smudge_cell', '17_Artifact', '18_nRBC', '19_Giant_platelet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23754959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "x, y = next(train_batches)\n",
    "new_ytrain = []\n",
    "for i in range(len(y)):\n",
    "    data = list(y[i])\n",
    "    index_ = data.index(1)\n",
    "    new_ytrain.append(index_)\n",
    "yy = np.array(new_ytrain)\n",
    "unique_, counts = np.unique(yy, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab56064",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoder = le.fit_transform(yy.flatten())\n",
    "y_train = y_encoder[:int(x.shape[0])]\n",
    "\n",
    "x_train = x\n",
    "\n",
    "unique_, counts = np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "x1, y1 = next(test_batches)\n",
    "new_ytest = []\n",
    "for i in range(len(y1)):\n",
    "    data = list(y1[i])\n",
    "    index_ = data.index(1)\n",
    "    new_ytest.append(index_)\n",
    "yy1 = np.array(new_ytest)\n",
    "\n",
    "unique, counts = np.unique(yy1, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40512e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoder = le.fit_transform(yy1.flatten())\n",
    "y_test = y_encoder[:int(x1.shape[0])]\n",
    "x_test = x1\n",
    "\n",
    "x_t = x1\n",
    "y_t= y_encoder[np.arange(int(x1.shape[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f44e8a",
   "metadata": {},
   "source": [
    "#### 3. Training the Model <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317635c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, Validating, and Testing loop for number of folds\n",
    "def func_cv(X_train, y_train, cv_itr, n_cv):\n",
    "    c_matrix_test = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    cm_agg = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    res_acc = np.zeros(n_cv)\n",
    "    res_pre = np.zeros(n_cv)\n",
    "    res_rec = np.zeros(n_cv)\n",
    "    res_f1s = np.zeros(n_cv)\n",
    "    \n",
    "    res_acc_ts = np.zeros(n_cv)\n",
    "    res_pre_ts = np.zeros(n_cv)\n",
    "    res_rec_ts = np.zeros(n_cv)\n",
    "    res_f1s_ts = np.zeros(n_cv)\n",
    "    \n",
    "    \n",
    "    ix = 0\n",
    "    \n",
    "    for train_ix, test_ix in cv_itr.split(X_train, y_train):\n",
    "        x_tr, y_tr = X_train[train_ix], y_train[train_ix]\n",
    "        x_val, y_val = X_train[test_ix], y_train[test_ix]      \n",
    "        \n",
    "        history = model1.fit(x_tr, y_tr,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            epochs= epochs,\n",
    "                            callbacks=[\n",
    "                                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                    monitor = 'val_accuracy',\n",
    "                                    factor = 0.2,\n",
    "                                    patience = 10,\n",
    "                                    verbose = 1,\n",
    "                                    min_delta = 1e-4,\n",
    "                                    min_lr = 1e-6,\n",
    "                                    mode = 'max'),\n",
    "\n",
    "                                tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor = 'val_accuracy',\n",
    "                                    min_delta = 1e-4,\n",
    "                                    patience = 25,\n",
    "                                    mode = 'max',\n",
    "                                    restore_best_weights = True,\n",
    "                                    verbose = 1),\n",
    "\n",
    "                                tf.keras.callbacks.ModelCheckpoint(\n",
    "                                    filepath = filepath1,\n",
    "                                    monitor = 'val_accuracy', \n",
    "                                    verbose = 1, \n",
    "                                    save_best_only = True,\n",
    "                                    save_weights_only = False,\n",
    "                                    mode = 'max')\n",
    "                            ])\n",
    "        \n",
    "        print(\"[INFO] saving model...\")\n",
    "        \n",
    "        # load a saved model\n",
    "        saved_model1 = tf.keras.models.load_model(\n",
    "            filepath1,\n",
    "            custom_objects=None,\n",
    "            compile=True,\n",
    "            options=None\n",
    "        )\n",
    "\n",
    "\n",
    "        # START ---TRAINING AND VALIDATION PART---\n",
    "        y_pred_ = saved_model1.predict(x_val)        \n",
    "        y_pred1 = []\n",
    "        y_pred2 = []\n",
    "        \n",
    "        \n",
    "        for i in y_pred_:\n",
    "            y_pred1.append(np.argmax(i)) \n",
    "        for j in y_val:\n",
    "            y_pred2.append(np.argmax(j))\n",
    "\n",
    "        y_pred = np.array(y_pred1)\n",
    "        y_pred_ts = np.array(y_pred2)\n",
    "               \n",
    "        \n",
    "        print('\\n\\n') \n",
    "        print('-'* 40)\n",
    "        print(time.strftime('%X %x %Z'))\n",
    "        print('{0}-CV Performance Metrics'.format(ix))\n",
    "        print('-'* 40)\n",
    "        \n",
    "        cr = classification_report(y_pred_ts, y_pred,labels=unique, digits=3, output_dict='true')\n",
    "        \n",
    "        res_acc[ix] = cr['accuracy']\n",
    "        res_pre[ix] = cr['macro avg']['precision']\n",
    "        res_rec[ix] = cr['macro avg']['recall']\n",
    "        res_f1s[ix] = cr['macro avg']['f1-score']\n",
    "        \n",
    "        \n",
    "        print('\\n\\n')\n",
    "        print('-'* 80)\n",
    "        print('Validation')\n",
    "        print('Accuracy:\\t\\t {0:.5f}'.format(cr['accuracy']))\n",
    "        print('Avg precision:\\t\\t {0:.5f}'.format(cr['macro avg']['precision']))\n",
    "        print('Avg recall:\\t\\t {0:.5f}'.format(cr['macro avg']['recall']))\n",
    "        print('Avg f1-score:\\t\\t {0:.5f}'.format(cr['macro avg']['f1-score']))\n",
    "          # END ---TRAINING AND VALIDATION PART---     \n",
    "\n",
    "        \n",
    "        # START ---TESTING PART---   \n",
    "        i = randint(2, 9)       \n",
    "        num_val = len(x_t)//i\n",
    "        x_test_ = x_t[num_val:(i+1)*num_val]\n",
    "        y_test_ = y1[num_val:(i+1)*num_val]\n",
    "        \n",
    "        y_pred_test = saved_model1.predict(x_test_) \n",
    "        \n",
    "        y_pred_test1 = []\n",
    "        y_pred_test2 = []\n",
    "        \n",
    "        for i in y_pred_test:\n",
    "            y_pred_test1.append(np.argmax(i)) \n",
    "        for j in y_test_:\n",
    "            y_pred_test2.append(np.argmax(j))\n",
    "            \n",
    "        y_pred_t = np.array(y_pred_test1)\n",
    "        y_pred_tt = np.array(y_pred_test2)\n",
    "        \n",
    "\n",
    "        # Testing Classification\n",
    "        c_matrix_test = confusion_matrix(y_pred_tt, y_pred_t)\n",
    "       \n",
    "        cm_agg = np.add(cm_agg, c_matrix_test) \n",
    "        \n",
    "        cr_test = classification_report(y_pred_tt, y_pred_t,labels=unique, digits=3, output_dict='true')\n",
    "        \n",
    "        #Testing\n",
    "        res_acc_ts[ix] = cr_test['accuracy']\n",
    "        res_pre_ts[ix] = cr_test['macro avg']['precision']\n",
    "        res_rec_ts[ix] = cr_test['macro avg']['recall']\n",
    "        res_f1s_ts[ix] = cr_test['macro avg']['f1-score']\n",
    "        \n",
    "        \n",
    "        print('\\n\\n')\n",
    "        print('Testing')\n",
    "        print('Accuracy_test:\\t\\t\\t {0:.5f}'.format(cr_test['accuracy']))\n",
    "        print('Avg precision_test:\\t\\t {0:.5f}'.format(cr_test['macro avg']['precision']))\n",
    "        print('Avg recall_test:\\t\\t {0:.5f}'.format(cr_test['macro avg']['recall']))\n",
    "        print('Avg f1-score_test:\\t\\t {0:.5f}'.format(cr_test['macro avg']['f1-score']))\n",
    "\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print('-'* 80)\n",
    "        ix = ix + 1  \n",
    "        \n",
    "        \n",
    "        \n",
    "    print('Aggregated metrics performance for Validation ')  \n",
    "    print('-'* 80)\n",
    "    print('Aggregated avg accuracy:\\t {0:.5f}'.format(np.mean(res_acc)))\n",
    "    print('Aggregated avg precision:\\t {0:.5f}'.format(np.mean(res_pre)))\n",
    "    print('Aggregated avg recall:\\t\\t {0:.5f}'.format(np.mean(res_rec)))\n",
    "    print('Aggregated avg f1-score:\\t {0:.5f}'.format(np.mean(res_f1s)))\n",
    "    print('')\n",
    "    \n",
    "    print('-'* 80)\n",
    "    print('Aggregated metrics performance for Testing')\n",
    "    print('-'* 80)\n",
    "    print('Aggregated AVG Accuracy_test:\\t {0:.5f}'.format(np.mean(res_acc_ts)))\n",
    "    print('Aggregated AVG Precision_test:\\t {0:.5f}'.format(np.mean(res_pre_ts)))\n",
    "    print('Aggregated AVG Recall_test:\\t {0:.5f}'.format(np.mean(res_rec_ts)))\n",
    "    print('Aggregated AVG f1-Score_test:\\t {0:.5f}'.format(np.mean(res_f1s_ts)))\n",
    "    print('')\n",
    "    print('')\n",
    "    print(\"\")\n",
    "    print('Normalized confusion_matrix')\n",
    "    print('')\n",
    "\n",
    "    def plot_confusion_matrix(cm_agg, classes,\n",
    "                        normalize=True,\n",
    "                        title='Normalized confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "                        \n",
    "        plt.imshow(cm_agg, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        # plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        if normalize:\n",
    "            cm_agg = np.around(cm_agg.astype('float') / cm_agg.sum(axis=1)[:, np.newaxis], decimals= 2)\n",
    "            print()\n",
    "            # print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print()\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        thresh = cm_agg.max() / 2.\n",
    "        for i, j in itertools.product(range(cm_agg.shape[0]), range(cm_agg.shape[1])):\n",
    "            plt.text(j, i, cm_agg[i, j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"black\" if cm_agg[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "    cm_plot_labels = ['01_Band_neutrophil', '02_Segmented_neutrophil', '03_Eosinophil', '04_Basophil', '05_Lymphocyte', '06_Monocyte', \n",
    "                      '07_Promyelocyte', '08_Myelocyte', '09_Metamyelocyte', '10_Prolymphocyte', '11_Immature_cell', '12_Lymphocyte_variant_form', \n",
    "                      '13_Plasma_cell', '14_Large_granular_lymphocyte', '15_Abnormal_cell', '16_Smudge_cell', '17_Artifact', '18_nRBC', '19_Giant_platelet']\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    plot_confusion_matrix(cm_agg=cm_agg, classes=cm_plot_labels, title='Normalized Confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cross_valid = 10\n",
    "kf = KFold(n_splits=n_cross_valid, shuffle=True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print('*'*80)\n",
    "print('*'*80)\n",
    "print(\"ResNet50_SVM_Classifier\")\n",
    "print(time.strftime('%X %x %Z'))\n",
    "\n",
    "print('*'*80)\n",
    "func_cv(x_train,y, kf, n_cross_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_tf_gpu",
   "language": "python",
   "name": "new_tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
